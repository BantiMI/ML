Данная нейросеть была создана для задачи много классовой классификации. Перед написанием серьезной модели, заточенной на распознавании рукописных цифр, мне необходимо было проверить работоспособность моего алгоритма и моей идеи на более мелкой модели. И в качестве проверки я выбрал модель по распознаванию марок машин. На вход программа получает 6 параметров. Каждый из параметров кодируется либо 0, либо 1. 

Эффективность использования топлива = 1 - эффективно, 0 - не эффективно
Возраст = 1 - новая, 0 - старая
Мощность = 1 - мощное, 0 - слабое
Премиальность = 1 - престижное, 0 - обычное
Простота устройства = 1 - простое, 0 - сложное
Цена = 1 - низкая, 0 - высокая

В скрытом слое нейросети содержится 9 нейронов, каждый из которых отвечает за определенные условия. В V1 версии нейросети я самостоятельно прописал все условия для нейронов и расставил веса соответствующих им связей, что позволило мне составить примеры для дальнейшего обучения нейросети.

1 нейрон - Дорогое + лакшери - БМВ(0,5) тайота (0,4) теста (0,1)
2 нейрон - Старое + лакшери - БМВ(0,5) тайота (0,5) тесла (0,1)
3 нейрон - Дешевое + лакшери - тайота (0,5) БМВ (0,4) теста (0,1)
4 нейрон - Мощное + старое - тайоту (0,5), БМВ (0,5)
5 нейрон - Эффективное топливо + простое - тайоту (0,6) БМВ (0,3) теста (0,1)
6 нейрон - Дорогое + лакшери + старое - тесла (0) БМВ(0,6) тайоту (0,4)
7 нейрон - Эффективный расход топлива + старое + дорогое + мощное + лакшери + простое - тайота (0,6) БМВ (0,4)
8 нейрон - Новое + дорогое + не простое - БМВ(0,4) теста (0,3) тайота (0,3)
9 нейрон - Эффективное топливо + молодая - тесла (0,8) БМВ (0,5) тайота(0,5)

Сначала прописано условие активации нейрона, т.е. сочетание необходимых признаков первого слоя. А затем указан вес связи от этого нейрона к трём нейронам выходного слоя.

Впервые в нейросетях я применил больше одного нейрона на выходном слое. В данной задаче их целых три. Поэтому пришлось использовать функцию активации Softmax, которая позволила перевести итоговую сумму на нейронах выходного слоя в процентные невероятности(приближено).

Значение весов всех связей первого и второго слоя я расставил самостоятельно и приписал в программе в массивы W1 и W2.

Следующим моим шагом был переход программы от ручного обновления весов к алгоритму backpropagation. Это вызвало некоторые трудности, так как взять производную от функции Softmax по аналогии с предыдущими нейросетями у меня не получилось. Я начал подробно изучать вопрос в интернете и наткнулся на статью, в которой рассказывалось, что функции Softmax используются в сочетании с кросс-энтропией, благодаря чему градиент ошибки высчитывается намного проще, то есть просто выход модели минус эталонное значение. Эта информация помогла мне проще реализовать алгоритм backpropagation.